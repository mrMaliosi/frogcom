# Руководство по оркестрации двух LLM моделей

## Обзор

FrogCom теперь поддерживает оркестрацию между двумя LLM моделями для улучшения качества генерации текста. Основная модель генерирует первичный ответ, а вторая модель анализирует его и предлагает уточнения для улучшения.

## Архитектура оркестрации

```
Пользователь → API → Оркестратор → Первичная модель
                                    ↓
                              Вторая модель (анализ)
                                    ↓
                              Первичная модель (доработка)
                                    ↓
                              Финальный ответ → Пользователь
```

## Конфигурация

### Переменные окружения

| Переменная | Описание | По умолчанию |
|------------|----------|--------------|
| `LLM_MODEL` | Основная модель | `facebook/opt-125m` |
| `LLM_MODEL_SECONDARY` | Вторая модель | `facebook/opt-125m` |
| `COMMUNICATION_ROUNDS` | Количество раундов общения | `1` |
| `SECONDARY_GOAL_PROMPT` | Целевой промпт второй модели | См. ниже |
| `ORCHESTRATION_ENABLED` | Включить оркестрацию | `true` |

### Целевой промпт второй модели

По умолчанию:
```
Ты — проверяющий ассистент. Проанализируй ответ и предложи уточняющие вопросы, 
которые помогут улучшить ответ. Верни только список вопросов или указания.
```

## API Эндпоинты

### 1. Генерация с оркестрацией

```http
POST /generate
Content-Type: application/json

{
  "prompt": "Объясни квантовую физику",
  "max_tokens": 200,
  "temperature": 0.7
}
```

### 2. Конфигурация оркестрации

#### Получение текущей конфигурации
```http
GET /config/orchestration
```

Ответ:
```json
{
  "enabled": true,
  "communication_rounds": 1,
  "secondary_goal_prompt": "Ты — проверяющий ассистент..."
}
```

#### Обновление конфигурации
```http
PUT /config/orchestration
Content-Type: application/json

{
  "enabled": true,
  "communication_rounds": 2,
  "secondary_goal_prompt": "Проанализируй ответ и предложи улучшения"
}
```

## Примеры использования

### Python

```python
import requests

# Генерация с оркестрацией
response = requests.post("http://localhost:8888/generate", json={
    "prompt": "Напиши краткое резюме статьи о машинном обучении",
    "max_tokens": 150,
    "temperature": 0.7
})

result = response.json()
print("Финальный ответ:", result["choices"][0]["message"]["content"])

# Настройка оркестрации
config_response = requests.put("http://localhost:8888/config/orchestration", json={
    "communication_rounds": 2,
    "secondary_goal_prompt": "Найди неточности и предложи дополнения"
})

print("Конфигурация обновлена:", config_response.json())
```

### JavaScript

```javascript
// Генерация с оркестрацией
const response = await fetch('http://localhost:8888/generate', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
        prompt: 'Объясни принцип работы блокчейна',
        max_tokens: 200
    })
});

const result = await response.json();
console.log('Ответ:', result.choices[0].message.content);

// Настройка оркестрации
const configResponse = await fetch('http://localhost:8888/config/orchestration', {
    method: 'PUT',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
        communication_rounds: 1,
        enabled: true
    })
});
```

## Трассировка

Все взаимодействия между моделями логируются в отдельный файл `logs/orchestration_trace.log` для анализа и отладки.

### Структура лога трассировки

```
================================================================================
TRACE START: frogcom-1705123456.789
================================================================================
{
  "trace_id": "frogcom-1705123456.789",
  "timestamp": "2024-01-15T10:30:00.000Z",
  "user_prompt": "Объясни квантовую физику",
  "orchestration_enabled": true,
  "steps": []
}

--- STEP 0 ---
{
  "step": 0,
  "type": "primary_response",
  "timestamp": "2024-01-15T10:30:01.000Z",
  "response": "Квантовая физика изучает поведение..."
}

--- STEP 1 ---
{
  "step": 1,
  "type": "secondary_guidance",
  "timestamp": "2024-01-15T10:30:02.000Z",
  "guidance": "1. Добавь примеры из повседневной жизни\n2. Объясни принцип неопределенности"
}

--- STEP 1 ---
{
  "step": 1,
  "type": "primary_response",
  "timestamp": "2024-01-15T10:30:03.000Z",
  "response": "Квантовая физика изучает поведение частиц...\n\nПример: лазер работает на принципах квантовой механики..."
}

--- STEP final ---
{
  "step": "final",
  "type": "final_response",
  "timestamp": "2024-01-15T10:30:04.000Z",
  "final_response": "Квантовая физика изучает поведение частиц..."
}
```

### Анализ трассировки

```bash
# Просмотр последних трассировок
tail -f logs/orchestration_trace.log

# Поиск конкретной трассировки
grep "TRACE START: frogcom-1705123456.789" logs/orchestration_trace.log -A 50

# Подсчет количества раундов
grep "secondary_guidance" logs/orchestration_trace.log | wc -l
```

## Настройка моделей

### Разные модели для разных ролей

```bash
# Основная модель для генерации
LLM_MODEL=facebook/opt-350m

# Вторая модель для анализа (может быть другой)
LLM_MODEL_SECONDARY=facebook/opt-125m

# Разные параметры для моделей
TEMPERATURE=0.7
TEMPERATURE_SECONDARY=0.5
```

### Отключение оркестрации

```bash
# Через переменную окружения
ORCHESTRATION_ENABLED=false

# Или через API
curl -X PUT "http://localhost:8888/config/orchestration" \
  -H "Content-Type: application/json" \
  -d '{"enabled": false}'
```

## Лучшие практики

### 1. Настройка промпта второй модели

- **Для технических тем**: "Найди неточности в терминологии и предложи более точные формулировки"
- **Для творческих задач**: "Предложи способы сделать текст более выразительным и интересным"
- **Для объяснений**: "Найди места, которые могут быть непонятны новичкам, и предложи упрощения"

### 2. Количество раундов

- **1 раунд**: Быстрая проверка и улучшение
- **2-3 раунда**: Глубокий анализ и доработка
- **Больше 3**: Может привести к избыточной обработке

### 3. Мониторинг

- Регулярно проверяйте логи трассировки
- Анализируйте эффективность уточнений второй модели
- Настраивайте промпты на основе анализа

## Troubleshooting

### Проблема: Медленная генерация
**Решение**: Уменьшите количество раундов или используйте более быстрые модели

### Проблема: Низкое качество уточнений
**Решение**: Настройте `SECONDARY_GOAL_PROMPT` для конкретной задачи

### Проблема: Избыточная обработка
**Решение**: Уменьшите `COMMUNICATION_ROUNDS` или отключите оркестрацию для простых задач

### Проблема: Ошибки в логах
**Решение**: Проверьте доступность обеих моделей и корректность конфигурации

## Примеры сценариев

### 1. Техническая документация
```json
{
  "communication_rounds": 2,
  "secondary_goal_prompt": "Проверь техническую точность, найди неточности в терминологии и предложи улучшения для ясности"
}
```

### 2. Творческое письмо
```json
{
  "communication_rounds": 1,
  "secondary_goal_prompt": "Предложи способы сделать текст более живым и эмоциональным"
}
```

### 3. Образовательный контент
```json
{
  "communication_rounds": 2,
  "secondary_goal_prompt": "Найди сложные места и предложи упрощения, добавь примеры для лучшего понимания"
}
```

## Производительность

### Рекомендации по оптимизации

1. **Используйте разные модели**: Основная модель может быть более мощной, вторая - более быстрой
2. **Настройте параметры**: Разные temperature и max_tokens для разных моделей
3. **Мониторинг ресурсов**: Следите за использованием GPU памяти
4. **Кэширование**: Рассмотрите кэширование для повторяющихся запросов

### Метрики для отслеживания

- Время генерации с оркестрацией vs без неё
- Качество финальных ответов
- Эффективность уточнений второй модели
- Использование ресурсов (GPU, память)
